{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def delete_model_jsons(model_name):\n",
    "    \"\"\"\n",
    "    Deletes JSON files for the specified model name across all indicators and countries.\n",
    "    Replaces spaces in country names with underscores.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model (e.g., \"XGBoost\", \"Prophet\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load country names and indicators\n",
    "    with open(\"../countries.json\", \"r\") as f:\n",
    "        country_names = json.load(f)\n",
    "    with open(\"../indicators.json\", \"r\") as f:\n",
    "        indicators = json.load(f)\n",
    "\n",
    "    # Define the base path for the parameter files\n",
    "    base_dir = \"../best_params\"\n",
    "\n",
    "    # Iterate over all indicators and countries to delete JSON files\n",
    "    for indicator in indicators.keys():\n",
    "        for country in country_names.keys():\n",
    "            # Replace spaces in the country name with underscores\n",
    "\n",
    "            # Construct the file path\n",
    "            json_file_path = os.path.join(base_dir, indicator, f\"{model_name}_{country}.json\")\n",
    "            \n",
    "            # Check if the file exists and delete it\n",
    "            if os.path.exists(json_file_path):\n",
    "                try:\n",
    "                    os.remove(json_file_path)\n",
    "                    print(f\"Deleted: {json_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {json_file_path}: {e}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "# Example usage:\n",
    "#delete_model_jsons(\"ARIMA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@sandha.iitr/tuning-arima-for-forecasting-an-easy-approach-in-python-5f40d55184c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_arima(train_y, test_y, country, indicator):\n",
    "    # Ensure the time index is correctly set\n",
    "    train_y.index = pd.date_range(start=train_y.index[0], periods=len(train_y), freq='YE')  # Assuming yearly data\n",
    "    test_y.index = pd.date_range(start=test_y.index[0], periods=len(test_y), freq='YE')\n",
    "\n",
    "    # Define paths for saving/loading best parameters\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"ARIMA_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the best parameters JSON file exists\n",
    "    if os.path.exists(params_file):\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "        print(f\"Loaded best parameters for {country} - {indicator} from {params_file}: {best_params}\")\n",
    "    else:\n",
    "        # Run the grid search if no parameters file exists\n",
    "        print(f\"No pre-existing parameters for {country} - {indicator}. Running grid search.\")\n",
    "        best_rmse = float('inf')\n",
    "        best_order = None\n",
    "        best_predictions = None\n",
    "\n",
    "        # Perform grid search over ARIMA orders (p, d, q)\n",
    "        for p in range(15):\n",
    "            for d in range(6):\n",
    "                for q in range(10):\n",
    "                    try:\n",
    "                        # Fit the ARIMA model\n",
    "                        model = ARIMA(train_y, order=(p, d, q))\n",
    "                        model_fit = model.fit()\n",
    "\n",
    "                        # Forecast and calculate RMSE\n",
    "                        predictions = model_fit.forecast(steps=len(test_y))\n",
    "                        rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "                        # Track the best parameters\n",
    "                        if rmse < best_rmse:\n",
    "                            best_rmse = rmse\n",
    "                            best_order = (p, d, q)\n",
    "                            best_predictions = predictions\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with parameters: p={p}, d={d}, q={q}. Error: {e}\")\n",
    "                        continue\n",
    "\n",
    "        # Save the best parameters to JSON for future use\n",
    "        if best_order is not None:\n",
    "            best_params = {\n",
    "                \"p\": best_order[0],\n",
    "                \"d\": best_order[1],\n",
    "                \"q\": best_order[2]\n",
    "            }\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "            print(f\"Saved best parameters for {country} - {indicator} to {params_file}: {best_params}\")\n",
    "\n",
    "    # Train the final model using the best parameters (loaded or discovered)\n",
    "    if best_params is not None:\n",
    "        best_order = (best_params[\"p\"], best_params[\"d\"], best_params[\"q\"])\n",
    "        model = ARIMA(train_y, order=best_order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Forecast using the final model\n",
    "        best_predictions = model_fit.forecast(steps=len(test_y))\n",
    "\n",
    "    # Save the predictions plot\n",
    "    if best_predictions is not None:\n",
    "        save_plot(train_y, test_y, best_predictions, country, indicator, model_name=\"ARIMA\")\n",
    "\n",
    "    return np.sqrt(mean_squared_error(test_y, best_predictions)), best_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "\n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "\n",
    "\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)]['ARIMA'],arime_pred = train_arima(df_original.iloc[:train_size]['Value'], \n",
    "                                                                               df_original.iloc[train_size:]['Value'], \n",
    "                                                                               country,indicator)\n",
    "\n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"ARIMA\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best parameters for Italy - GDP growth (annual %) from ../best_params\\GDP growth (annual %)\\ARIMA_Italy.json: {'p': 13, 'd': 0, 'q': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Desktop\\diplomovka\\Code\\Model_staff\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "c:\\Users\\admin\\Desktop\\diplomovka\\Code\\Model_staff\\myenv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      "c:\\Users\\admin\\Desktop\\diplomovka\\Code\\Model_staff\\myenv\\Lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_1188\\2416340231.py:186: FutureWarning: 'A' is deprecated and will be removed in a future version, please use 'Y' instead.\n",
      "  arime_pred.index = arime_pred.index.to_period('A').to_timestamp()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_arima(train_y, test_y, country, indicator):\n",
    "    # Ensure the time index is correctly set\n",
    "    train_y.index = pd.date_range(start=train_y.index[0], periods=len(train_y), freq='YE')  # Assuming yearly data\n",
    "    test_y.index = pd.date_range(start=test_y.index[0], periods=len(test_y), freq='YE')\n",
    "\n",
    "    # Define paths for saving/loading best parameters\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"ARIMA_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the best parameters JSON file exists\n",
    "    if os.path.exists(params_file):\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "        print(f\"Loaded best parameters for {country} - {indicator} from {params_file}: {best_params}\")\n",
    "    else:\n",
    "        # Run the grid search if no parameters file exists\n",
    "        print(f\"No pre-existing parameters for {country} - {indicator}. Running grid search.\")\n",
    "        best_rmse = float('inf')\n",
    "        best_order = None\n",
    "        best_predictions = None\n",
    "\n",
    "        # Perform grid search over ARIMA orders (p, d, q)\n",
    "        for p in range(15):\n",
    "            for d in range(6):\n",
    "                for q in range(10):\n",
    "                    try:\n",
    "                        # Fit the ARIMA model\n",
    "                        model = ARIMA(train_y, order=(p, d, q))\n",
    "                        model_fit = model.fit()\n",
    "\n",
    "                        # Forecast and calculate RMSE\n",
    "                        predictions = model_fit.forecast(steps=len(test_y))\n",
    "                        rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "                        # Track the best parameters\n",
    "                        if rmse < best_rmse:\n",
    "                            best_rmse = rmse\n",
    "                            best_order = (p, d, q)\n",
    "                            best_predictions = predictions\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with parameters: p={p}, d={d}, q={q}. Error: {e}\")\n",
    "                        continue\n",
    "\n",
    "        # Save the best parameters to JSON for future use\n",
    "        if best_order is not None:\n",
    "            best_params = {\n",
    "                \"p\": best_order[0],\n",
    "                \"d\": best_order[1],\n",
    "                \"q\": best_order[2]\n",
    "            }\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "            print(f\"Saved best parameters for {country} - {indicator} to {params_file}: {best_params}\")\n",
    "\n",
    "    # Train the final model using the best parameters (loaded or discovered)\n",
    "    if best_params is not None:\n",
    "        best_order = (best_params[\"p\"], best_params[\"d\"], best_params[\"q\"])\n",
    "        model = ARIMA(train_y, order=best_order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Forecast using the final model\n",
    "        best_predictions = model_fit.forecast(steps=len(test_y))\n",
    "\n",
    "    # Save the predictions plot\n",
    "    if best_predictions is not None:\n",
    "        save_plot(train_y, test_y, best_predictions, country, indicator, model_name=\"ARIMA\")\n",
    "\n",
    "    return np.sqrt(mean_squared_error(test_y, best_predictions)), best_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "\n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "\n",
    "\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)]['ARIMA'],arime_pred = train_arima(df_original.iloc[:train_size]['Value'], \n",
    "                                                                               df_original.iloc[train_size:]['Value'], \n",
    "                                                                               country,indicator)\n",
    "\n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"ARIMA\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD VERSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA_error_log_2025-02-16--05-58\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_arima(train_y, test_y, country, indicator):\n",
    "    # Ensure the time index is correctly set\n",
    "    train_y.index = pd.date_range(start=train_y.index[0], periods=len(train_y), freq='YE')  # Assuming yearly data\n",
    "    test_y.index = pd.date_range(start=test_y.index[0], periods=len(test_y), freq='YE')\n",
    "\n",
    "    # Define paths for saving/loading best parameters\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"ARIMA_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the best parameters JSON file exists\n",
    "    if os.path.exists(params_file):\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "        print(f\"Loaded best parameters for {country} - {indicator} from {params_file}: {best_params}\")\n",
    "    else:\n",
    "        # Run the grid search if no parameters file exists\n",
    "        print(f\"No pre-existing parameters for {country} - {indicator}. Running grid search.\")\n",
    "        best_rmse = float('inf')\n",
    "        best_order = None\n",
    "        best_predictions = None\n",
    "\n",
    "        # Perform grid search over ARIMA orders (p, d, q)\n",
    "        for p in range(15):\n",
    "            for d in range(6):\n",
    "                for q in range(10):\n",
    "                    try:\n",
    "                        # Fit the ARIMA model\n",
    "                        model = ARIMA(train_y, order=(p, d, q))\n",
    "                        model_fit = model.fit()\n",
    "\n",
    "                        # Forecast and calculate RMSE\n",
    "                        predictions = model_fit.forecast(steps=len(test_y))\n",
    "                        rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "                        # Track the best parameters\n",
    "                        if rmse < best_rmse:\n",
    "                            best_rmse = rmse\n",
    "                            best_order = (p, d, q)\n",
    "                            best_predictions = predictions\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with parameters: p={p}, d={d}, q={q}. Error: {e}\")\n",
    "                        continue\n",
    "\n",
    "        # Save the best parameters to JSON for future use\n",
    "        if best_order is not None:\n",
    "            best_params = {\n",
    "                \"p\": best_order[0],\n",
    "                \"d\": best_order[1],\n",
    "                \"q\": best_order[2]\n",
    "            }\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "            print(f\"Saved best parameters for {country} - {indicator} to {params_file}: {best_params}\")\n",
    "\n",
    "    # Train the final model using the best parameters (loaded or discovered)\n",
    "    if best_params is not None:\n",
    "        best_order = (best_params[\"p\"], best_params[\"d\"], best_params[\"q\"])\n",
    "        model = ARIMA(train_y, order=best_order)\n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Forecast using the final model\n",
    "        best_predictions = model_fit.forecast(steps=len(test_y))\n",
    "\n",
    "    # Save the predictions plot\n",
    "    if best_predictions is not None:\n",
    "        save_plot(train_y, test_y, best_predictions, country, indicator, model_name=\"ARIMA\")\n",
    "\n",
    "    return np.sqrt(mean_squared_error(test_y, best_predictions)), best_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "\n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "\n",
    "\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)]['ARIMA'],arime_pred = train_arima(df_original.iloc[:train_size]['Value'], \n",
    "                                                                               df_original.iloc[train_size:]['Value'], \n",
    "                                                                               country,indicator)\n",
    "\n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"ARIMA\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ARIMA_error_log_2025-02-11--22-03\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_arima(train_y, test_y, country, indicator):\n",
    "    best_rmse = float('inf')\n",
    "    best_order = None\n",
    "    best_predictions = None\n",
    "\n",
    "    for p in range(4):\n",
    "        for d in range(4):\n",
    "            for q in range(4):\n",
    "                try:\n",
    "                    # Fit the ARIMA model\n",
    "                    model = ARIMA(train_y, order=(p, d, q))\n",
    "                    model_fit = model.fit()\n",
    "                    \n",
    "                    predictions = model_fit.forecast(steps=len(test_y))\n",
    "                    rmse = np.sqrt(mean_squared_error(test_y, predictions))\n",
    "\n",
    "                    if rmse < best_rmse:\n",
    "                        best_rmse = rmse\n",
    "                        best_order = (p, d, q)\n",
    "                        best_predictions = predictions\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "    # After finding the best model, save the predictions plot\n",
    "    if best_predictions is not None:\n",
    "        save_plot(train_y, test_y, best_predictions, country, indicator, model_name=\"ARIMA\")\n",
    "\n",
    "    return best_rmse , best_predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "\n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "\n",
    "\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)]['ARIMA'],arime_pred = train_arima(df_original.iloc[:train_size]['Value'], \n",
    "                                                                               df_original.iloc[train_size:]['Value'], \n",
    "                                                                               country,indicator)\n",
    "\n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"ARIMA\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
