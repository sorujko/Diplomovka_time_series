{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def delete_model_jsons(model_name):\n",
    "    \"\"\"\n",
    "    Deletes JSON files for the specified model name across all indicators and countries.\n",
    "    Replaces spaces in country names with underscores.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model (e.g., \"XGBoost\", \"Prophet\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load country names and indicators\n",
    "    with open(\"../countries.json\", \"r\") as f:\n",
    "        country_names = json.load(f)\n",
    "    with open(\"../indicators.json\", \"r\") as f:\n",
    "        indicators = json.load(f)\n",
    "\n",
    "    # Define the base path for the parameter files\n",
    "    base_dir = \"../best_params\"\n",
    "\n",
    "    # Iterate over all indicators and countries to delete JSON files\n",
    "    for indicator in indicators.keys():\n",
    "        for country in country_names.keys():\n",
    "            # Replace spaces in the country name with underscores\n",
    "\n",
    "            # Construct the file path\n",
    "            json_file_path = os.path.join(base_dir, indicator, f\"{model_name}_{country}.json\")\n",
    "            \n",
    "            # Check if the file exists and delete it\n",
    "            if os.path.exists(json_file_path):\n",
    "                try:\n",
    "                    os.remove(json_file_path)\n",
    "                    print(f\"Deleted: {json_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {json_file_path}: {e}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "# Example usage:\n",
    "delete_model_jsons(\"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n"
     ]
    }
   ],
   "source": [
    "#XGBoost_error_log_2025-02-14--19-26\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean_3'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_3'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_3'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_3'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 5  \n",
    "                df['rolling_mean_5'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_5'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_5'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_5'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 4  \n",
    "                df['rolling_mean_4'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_4'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_4'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_4'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 2  \n",
    "                df['rolling_mean_2'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_2'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_2'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_2'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean_2', 'rolling_std_2', 'rolling_max_2', 'rolling_min_2', \n",
    "                                   'rolling_mean_3', 'rolling_std_3', 'rolling_max_3', 'rolling_min_3',\n",
    "                                   'rolling_mean_4', 'rolling_std_4', 'rolling_max_4', 'rolling_min_4',\n",
    "                                   'rolling_mean_5', 'rolling_std_5', 'rolling_max_5', 'rolling_min_5', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3',]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n"
     ]
    }
   ],
   "source": [
    "#XGBoost_error_log_2025-02-14--19-26\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean_3'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_3'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_3'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_3'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 5  \n",
    "                df['rolling_mean_5'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_5'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_5'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_5'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 4  \n",
    "                df['rolling_mean_4'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_4'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_4'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_4'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 2  \n",
    "                df['rolling_mean_2'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_2'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_2'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_2'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean_2', 'rolling_std_2', 'rolling_max_2', 'rolling_min_2', \n",
    "                                   'rolling_mean_3', 'rolling_std_3', 'rolling_max_3', 'rolling_min_3',\n",
    "                                   'rolling_mean_4', 'rolling_std_4', 'rolling_max_4', 'rolling_min_4',\n",
    "                                   'rolling_mean_5', 'rolling_std_5', 'rolling_max_5', 'rolling_min_5', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3',]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STARSIE VERZIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost_error_log_2025-02-14--19-26\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean_3'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_3'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_3'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_3'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 5  \n",
    "                df['rolling_mean_5'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_5'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_5'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_5'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 4  \n",
    "                df['rolling_mean_4'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_4'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_4'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_4'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 2  \n",
    "                df['rolling_mean_2'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_2'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_2'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_2'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean_2', 'rolling_std_2', 'rolling_max_2', 'rolling_min_2', \n",
    "                                   'rolling_mean_3', 'rolling_std_3', 'rolling_max_3', 'rolling_min_3',\n",
    "                                   'rolling_mean_4', 'rolling_std_4', 'rolling_max_4', 'rolling_min_4',\n",
    "                                   'rolling_mean_5', 'rolling_std_5', 'rolling_max_5', 'rolling_min_5', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3',]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost_error_log_2025-02-14--19-11\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean_3'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_3'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_3'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_3'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 5  \n",
    "                df['rolling_mean_5'] = df['Value'].rolling(window=window_size, min_periods=3).mean()\n",
    "                df['rolling_std_5'] = df['Value'].rolling(window=window_size, min_periods=3).std()\n",
    "                df['rolling_max_5'] = df['Value'].rolling(window=window_size, min_periods=3).max()\n",
    "                df['rolling_min_5'] = df['Value'].rolling(window=window_size, min_periods=3).min()\n",
    "\n",
    "                window_size = 4  \n",
    "                df['rolling_mean_4'] = df['Value'].rolling(window=window_size, min_periods=2).mean()\n",
    "                df['rolling_std_4'] = df['Value'].rolling(window=window_size, min_periods=2).std()\n",
    "                df['rolling_max_4'] = df['Value'].rolling(window=window_size, min_periods=2).max()\n",
    "                df['rolling_min_4'] = df['Value'].rolling(window=window_size, min_periods=2).min()\n",
    "\n",
    "                window_size = 2  \n",
    "                df['rolling_mean_2'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_2'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_2'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_2'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean_2', 'rolling_std_2', 'rolling_max_2', 'rolling_min_2', \n",
    "                                   'rolling_mean_3', 'rolling_std_3', 'rolling_max_3', 'rolling_min_3',\n",
    "                                   'rolling_mean_4', 'rolling_std_4', 'rolling_max_4', 'rolling_min_4',\n",
    "                                   'rolling_mean_5', 'rolling_std_5', 'rolling_max_5', 'rolling_min_5', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3',]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost_error_log_2025-02-14--18-40\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean_3'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_3'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_3'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_3'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 4  \n",
    "                df['rolling_mean_4'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_4'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_4'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_4'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "\n",
    "                window_size = 2  \n",
    "                df['rolling_mean_2'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std_2'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max_2'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min_2'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean_2', 'rolling_std_2', 'rolling_max_2', 'rolling_min_2', \n",
    "                                   'rolling_mean_3', 'rolling_std_3', 'rolling_max_3', 'rolling_min_3',\n",
    "                                   'rolling_mean_4', 'rolling_std_4', 'rolling_max_4', 'rolling_min_4', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3',]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 6):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean', 'rolling_std', 'rolling_max', 'rolling_min', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense , Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y,country,indicator):\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    top_n_features=4\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.05],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "\n",
    "    # Initialize the XGBoost regressor\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "    # Perform GridSearchCV to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(train_x, train_y)\n",
    "\n",
    "    # Get the best model from GridSearchCV\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Select the top N important features based on RFE\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "with open(\"countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 6):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean', 'rolling_std', 'rolling_max', 'rolling_min', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                model_errors_rmse[(country, indicator)]['ARIMA'],arime_pred = train_arima(df_original.iloc[:train_size]['Value'], \n",
    "                                                                               df_original.iloc[train_size:]['Value'], \n",
    "                                                                               country,indicator)\n",
    "                model_errors_rmse[(country, indicator)]['Holt-Winters'] , es_pred = train_holt_winters(df_original.iloc[:train_size]['Value'], \n",
    "                                                                                             df_original.iloc[train_size:]['Value'],\n",
    "                                                                                             country,indicator)\n",
    "                model_errors_rmse[(country, indicator)]['LSTM'] , lstm_pred = train_lstm(df_original.iloc[:train_size]['Value'], \n",
    "                                                                             df_original.iloc[train_size:]['Value'],\n",
    "                                                                             country,indicator)\n",
    "\n",
    "\n",
    "                prophet_train_df = df_original.iloc[:train_size].reset_index().rename(columns={'Year': 'ds', 'Value': 'y'})\n",
    "                prophet_test_df = df_original.iloc[train_size:].reset_index().rename(columns={'Year': 'ds', 'Value': 'y'})\n",
    "                prophet_train_df['ds'] = pd.to_datetime(prophet_train_df['ds'])\n",
    "                prophet_test_df['ds'] = pd.to_datetime(prophet_test_df['ds'])\n",
    "                model_errors_rmse[(country, indicator)]['Prophet'] , prop_error = train_prophet(prophet_train_df, prophet_test_df,\n",
    "                                                                                   country,indicator)\n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "                \n",
    "                model_ranks = {(entry[0], entry[1], entry[2]): entry[4] for entry in log_current_data}\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(df_original.iloc[:train_size].index, df_original.iloc[:train_size]['Value'], \n",
    "                         label='Train Data', color='green', linestyle='--')\n",
    "                plt.plot(df_original.iloc[train_size:].index, df_original.iloc[train_size:]['Value'],\n",
    "                          label='Test Data', color='red', linestyle='--')\n",
    "                \n",
    "                plt.plot(df_original.iloc[train_size:].index, arime_pred, \n",
    "                         label=f'ARIMA ({model_ranks.get((country, indicator, \"ARIMA\"), \"N/A\")})', \n",
    "                         color='blue', linestyle='-', marker='o')\n",
    "                \n",
    "                plt.plot(df_original.iloc[train_size:].index, es_pred, \n",
    "                          label=f'Holt-Winters ({model_ranks.get((country, indicator, \"Holt-Winters\"), \"N/A\")})',\n",
    "                         color='yellow',linestyle='-', marker='o')\n",
    "                \n",
    "                plt.plot(df_original.iloc[train_size:].index, lstm_pred, \n",
    "                         label=f'LSTM ({model_ranks.get((country, indicator, \"LSTM\"), \"N/A\")})', \n",
    "                         color='black', linestyle='-', marker='o')\n",
    "                \n",
    "                plt.plot(df_original.iloc[train_size:].index, xgb_pred, \n",
    "                         label=f'XGBoost ({model_ranks.get((country, indicator, \"XGBoost\"), \"N/A\")})', \n",
    "                         color='pink', linestyle='-', marker='o')\n",
    "                \n",
    "                plt.plot(df_original.iloc[train_size:].index, prop_error, \n",
    "                         label=f'Prophet ({model_ranks.get((country, indicator, \"Prophet\"), \"N/A\")})', \n",
    "                         color='brown', linestyle='-', marker='o')\n",
    "                \n",
    "                \n",
    "                plt.title(f'Predicted vs Actual for {country} - {indicator}')\n",
    "                plt.xlabel('Year')\n",
    "                plt.ylabel('Value')\n",
    "                plt.legend()\n",
    "\n",
    "                # Create subfolder for the indicator if it doesn't exist\n",
    "                indicator_folder = os.path.join('images', 'model_plot', 'Indicators', indicator)\n",
    "                os.makedirs(indicator_folder, exist_ok=True)\n",
    "                \n",
    "                # Save the plot in the Indicators folder with dynamic model name\n",
    "                plot_filename_indicator = os.path.join(indicator_folder, f'AllModels_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "                plt.savefig(plot_filename_indicator)\n",
    "\n",
    "                # Create subfolder for the country if it doesn't exist\n",
    "                country_folder = os.path.join('images', 'model_plot', 'Countries', country)\n",
    "                os.makedirs(country_folder, exist_ok=True)\n",
    "                \n",
    "                # Save the same plot in the Countries folder with dynamic model name\n",
    "                plot_filename_country = os.path.join(country_folder, f'AllModels_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "                plt.savefig(plot_filename_country)\n",
    "\n",
    "                \n",
    "                #plt.savefig(f'Predicted vs Actual for {country} - {indicator}')\n",
    "\n",
    "                if country not in country_indicators_plots:\n",
    "                    country_indicators_plots[country] = []\n",
    "                country_indicators_plots[country].append(plt.gcf())\n",
    "                plt.close()\n",
    "\n",
    "# After collecting all plots for each country, create a combined plot\n",
    "for country, plots in country_indicators_plots.items():\n",
    "    n_plots = len(plots)\n",
    "    n_cols = 2  # Set number of columns in the grid\n",
    "    n_rows = (n_plots + 1) // n_cols  # Calculate required number of rows\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * n_rows))  # Adjust figure size for grid layout\n",
    "    for i, plot in enumerate(plots, start=1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        \n",
    "        # Copy each plot's data by extracting from the original plot and plotting again\n",
    "        for ax in plot.get_axes():  # Iterate through all axes in the current plot\n",
    "            for line in ax.get_lines():  # Get lines (or other elements) from the original plot\n",
    "                plt.plot(line.get_xdata(), line.get_ydata(), label=line.get_label(), color=line.get_color(), linestyle=line.get_linestyle(), marker=line.get_marker())\n",
    "        \n",
    "        indicator_name = list(indicators.keys())[i - 1]\n",
    "        plt.title(f'{country} - {indicator_name}')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "\n",
    "    # Save the combined plot\n",
    "    country_folder = os.path.join('images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    plot_filename_country = os.path.join(country_folder, f'AllIndicators_{country.replace(\" \", \"_\")}.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_filename_country)\n",
    "    plt.close()\n",
    "\n",
    "# Create a dictionary to store all indicator plots for later use\n",
    "indicator_plots = {indicator: [] for indicator in indicators.keys()}\n",
    "\n",
    "# After collecting all plots for each country, create a combined plot for each indicator\n",
    "for country, plots in country_indicators_plots.items():\n",
    "    for i, plot in enumerate(plots, start=1):\n",
    "        indicator_name = list(indicators.keys())[i - 1]\n",
    "        \n",
    "        # Append each plot to the corresponding indicator's list\n",
    "        indicator_plots[indicator_name].append(plot)\n",
    "\n",
    "# Now create a combined plot for all countries for each indicator\n",
    "for indicator, plots in indicator_plots.items():\n",
    "    n_plots = len(plots)\n",
    "    n_cols = 2  # Set number of columns in the grid\n",
    "    n_rows = (n_plots + 1) // n_cols  # Calculate required number of rows\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * n_rows))  # Adjust figure size for grid layout\n",
    "    for i, plot in enumerate(plots, start=1):\n",
    "        plt.subplot(n_rows, n_cols, i)\n",
    "        \n",
    "        # Copy each plot's data by extracting from the original plot and plotting again\n",
    "        for ax in plot.get_axes():  # Iterate through all axes in the current plot\n",
    "            for line in ax.get_lines():  # Get lines (or other elements) from the original plot\n",
    "                plt.plot(line.get_xdata(), line.get_ydata(), label=line.get_label(), color=line.get_color(), linestyle=line.get_linestyle(), marker=line.get_marker())\n",
    "        \n",
    "        plt.title(f'{indicator} - {list(country_names)[i-1]}')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "\n",
    "    # Save the combined plot for the indicator across all countries\n",
    "    indicator_folder = os.path.join('images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'AllCountries_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "    plt.close()\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(\"model_error_log.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 400, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Split train data into training and validation sets\n",
    "        train_x_split, val_x_split, train_y_split, val_y_split = train_test_split(\n",
    "            train_x, train_y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42,\n",
    "            eval_metric='rmse',\n",
    "            early_stopping_rounds=30\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(\n",
    "            train_x_split, \n",
    "            train_y_split,\n",
    "            eval_set=[(val_x_split, val_y_split)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42,\n",
    "            eval_metric='rmse'\n",
    "        )\n",
    "\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "        print(\"Top 3 Selected Features:\")\n",
    "        for feature in selected_features:\n",
    "            print(feature)\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "        \n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 400, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Recursive Feature Elimination (RFE)\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.5,0.7,0.9,1],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Recursive Feature Elimination (RFE)\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        #predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        predictions_rfe = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Calculate RMSE for the RFE model\n",
    "        rmse_rfe = np.sqrt(mean_squared_error(test_y, predictions_rfe))\n",
    "\n",
    "        # Feature importance analysis\n",
    "        feature_importances = best_model.feature_importances_\n",
    "        important_features = selected_features[feature_importances > 0.1]\n",
    "\n",
    "        if len(important_features) > 0:\n",
    "            # Retrain the model using only features with importance > 0.1\n",
    "            best_model.fit(train_x[important_features], train_y, verbose=0)\n",
    "            predictions_important = best_model.predict(test_x[important_features])\n",
    "\n",
    "            # Calculate RMSE for the model trained on important features\n",
    "            rmse_important = np.sqrt(mean_squared_error(test_y, predictions_important))\n",
    "\n",
    "        if rmse_important >rmse_rfe:\n",
    "            predictions = predictions_important\n",
    "        else:\n",
    "            predictions = predictions_rfe\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
