{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\GDP per Capita (USD)\\XGBoost_Italy.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\GDP (USD)\\XGBoost_Italy.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\Inflation (CPI)\\XGBoost_Italy.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\Unemployment Rate (%)\\XGBoost_Italy.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\GDP growth (annual %)\\XGBoost_Italy.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\Imports of goods and services (% of GDP)\\XGBoost_Italy.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Czech Republic.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Hungary.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Poland.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Slovakia.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Germany.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Austria.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_France.json\n",
      "Deleted: ../best_params\\Exports of goods and services (% of GDP)\\XGBoost_Italy.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def delete_model_jsons(model_name):\n",
    "    \"\"\"\n",
    "    Deletes JSON files for the specified model name across all indicators and countries.\n",
    "    Replaces spaces in country names with underscores.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model (e.g., \"XGBoost\", \"Prophet\").\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load country names and indicators\n",
    "    with open(\"../countries.json\", \"r\") as f:\n",
    "        country_names = json.load(f)\n",
    "    with open(\"../indicators.json\", \"r\") as f:\n",
    "        indicators = json.load(f)\n",
    "\n",
    "    # Define the base path for the parameter files\n",
    "    base_dir = \"../best_params\"\n",
    "\n",
    "    # Iterate over all indicators and countries to delete JSON files\n",
    "    for indicator in indicators.keys():\n",
    "        for country in country_names.keys():\n",
    "            # Replace spaces in the country name with underscores\n",
    "\n",
    "            # Construct the file path\n",
    "            json_file_path = os.path.join(base_dir, indicator, f\"{model_name}_{country}.json\")\n",
    "            \n",
    "            # Check if the file exists and delete it\n",
    "            if os.path.exists(json_file_path):\n",
    "                try:\n",
    "                    os.remove(json_file_path)\n",
    "                    print(f\"Deleted: {json_file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error deleting {json_file_path}: {e}\")\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "# Example usage:\n",
    "delete_model_jsons(\"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define the parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 600, 700, 800, 900, 1000],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'max_depth': [3, 4, 5, 6]\n",
    "        }\n",
    "\n",
    "        # Initialize the XGBoost regressor\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "        # Perform GridSearchCV to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=0)\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters and save them to JSON\n",
    "        best_params = grid_search.best_params_\n",
    "        os.makedirs(params_dir, exist_ok=True)\n",
    "        with open(params_file, \"w\") as f:\n",
    "            json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using the loaded or selected parameters\n",
    "    best_model = xgb.XGBRegressor(\n",
    "        n_estimators=best_params['n_estimators'],\n",
    "        learning_rate=best_params['learning_rate'],\n",
    "        max_depth=best_params['max_depth'],\n",
    "        objective='reg:squarederror'\n",
    "    )\n",
    "\n",
    "    # Perform Recursive Feature Elimination (RFE)\n",
    "    top_n_features = 4\n",
    "    selector = RFE(estimator=best_model, n_features_to_select=top_n_features)\n",
    "    selector = selector.fit(train_x, train_y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = train_x.columns[selector.support_]\n",
    "\n",
    "    # Save selected features to JSON\n",
    "    features_file = os.path.join(params_dir, f\"SelectedFeatures_{country}.json\")\n",
    "    with open(features_file, \"w\") as f:\n",
    "        json.dump(selected_features.tolist(), f, indent=4)\n",
    "\n",
    "    # Transform data based on selected features\n",
    "    selected_train_x = selector.transform(train_x)\n",
    "    selected_test_x = selector.transform(test_x)\n",
    "\n",
    "    # Train the model again with the selected features\n",
    "    best_model.fit(selected_train_x, train_y)\n",
    "\n",
    "    # Make predictions on the test set using the selected features\n",
    "    predictions = best_model.predict(selected_test_x)\n",
    "\n",
    "    # Save the plot\n",
    "    save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "    # Calculate the RMSE on the test set\n",
    "    return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 6):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean', 'rolling_std', 'rolling_max', 'rolling_min', \n",
    "                                   'expanding_mean', 'expanding_std', 'expanding_max', 'expanding_min',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5']\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n",
      "No saved parameters found, performing grid search...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.5,0.7,0.9,1],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Recursive Feature Elimination (RFE)\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        #predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        predictions_rfe = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Calculate RMSE for the RFE model\n",
    "        rmse_rfe = np.sqrt(mean_squared_error(test_y, predictions_rfe))\n",
    "\n",
    "        # Feature importance analysis\n",
    "        feature_importances = best_model.feature_importances_\n",
    "        important_features = selected_features[feature_importances > 0.1]\n",
    "\n",
    "        if len(important_features) > 0:\n",
    "            # Retrain the model using only features with importance > 0.1\n",
    "            best_model.fit(train_x[important_features], train_y, verbose=0)\n",
    "            predictions_important = best_model.predict(test_x[important_features])\n",
    "\n",
    "            # Calculate RMSE for the model trained on important features\n",
    "            rmse_important = np.sqrt(mean_squared_error(test_y, predictions_important))\n",
    "\n",
    "        if rmse_important >rmse_rfe:\n",
    "            predictions = predictions_important\n",
    "        else:\n",
    "            predictions = predictions_rfe\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STARSIE VERZIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 400, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Split train data into training and validation sets\n",
    "        train_x_split, val_x_split, train_y_split, val_y_split = train_test_split(\n",
    "            train_x, train_y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42,\n",
    "            eval_metric='rmse',\n",
    "            early_stopping_rounds=30\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(\n",
    "            train_x_split, \n",
    "            train_y_split,\n",
    "            eval_set=[(val_x_split, val_y_split)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42,\n",
    "            eval_metric='rmse'\n",
    "        )\n",
    "\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "        print(\"Top 3 Selected Features:\")\n",
    "        for feature in selected_features:\n",
    "            print(feature)\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "        \n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 400, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Recursive Feature Elimination (RFE)\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def save_plot(train, test_y, predictions, country, indicator, model_name):\n",
    "    \"\"\"Function to save the plot in both Indicators and Countries folders.\"\"\"\n",
    "\n",
    "    model_colors = {\n",
    "    \"ARIMA\": \"blue\",\n",
    "    \"Holt_Winters\": \"yellow\",\n",
    "    \"LSTM\": \"black\",\n",
    "    \"XGBoost\": \"pink\",\n",
    "    \"Prophet\": \"brown\"\n",
    "}\n",
    "\n",
    "    # Plotting predicted vs actual\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if model_name == \"Prophet\":\n",
    "        plt.plot(train['ds'], train['y'], label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y['ds'], test_y['y'], label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y['ds'], predictions, label=f'Predicted({model_name})', color=f'{model_colors[\"Prophet\"]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    else:\n",
    "        plt.plot(train.index, train, label='Train Data', color='green', linestyle='--')\n",
    "        plt.plot(test_y.index, test_y, label='Actual', color='red', linestyle='--')\n",
    "        plt.plot(test_y.index, predictions, label=f'Predicted({model_name})', color=f'{model_colors[model_name]}', \n",
    "                 linestyle='-', marker='o')\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.title(f'Predicted({model_name}) vs Actual for {country} - {indicator}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "\n",
    "    # Create subfolder for the indicator if it doesn't exist\n",
    "    indicator_folder = os.path.join('../images', 'model_plot', 'Indicators', indicator)\n",
    "    os.makedirs(indicator_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the plot in the Indicators folder with dynamic model name\n",
    "    plot_filename_indicator = os.path.join(indicator_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_indicator)\n",
    "\n",
    "    # Create subfolder for the country if it doesn't exist\n",
    "    country_folder = os.path.join('../images', 'model_plot', 'Countries', country)\n",
    "    os.makedirs(country_folder, exist_ok=True)\n",
    "    \n",
    "    # Save the same plot in the Countries folder with dynamic model name\n",
    "    plot_filename_country = os.path.join(country_folder, f'{model_name}_{country.replace(\" \", \"_\")}_{indicator.replace(\" \", \"_\")}.png')\n",
    "    plt.savefig(plot_filename_country)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def train_xgboost(train_x, train_y, test_x, test_y, country, indicator):\n",
    "    params_dir = os.path.join(\"../best_params\", indicator)\n",
    "    params_file = os.path.join(params_dir, f\"XGBoost_{country}.json\")\n",
    "    best_params = None\n",
    "\n",
    "    # Check if the parameter file exists\n",
    "    if os.path.exists(params_file):\n",
    "        print(f\"Loading parameters from {params_file}...\")\n",
    "        with open(params_file, \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    else:\n",
    "        print(\"No saved parameters found, performing grid search...\")\n",
    "\n",
    "        # Define parameter grid for GridSearchCV\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200, 500, 700, 900],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'min_child_weight': [1, 3],\n",
    "            'gamma': [0, 0.1, 0.3],\n",
    "            'subsample': [0.5,0.7,0.9,1],\n",
    "            'colsample_bytree': [0.8, 1.0]\n",
    "        }\n",
    "\n",
    "        # Initialize the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror', \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Set up the grid search with cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            verbose=0,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(train_x, train_y)\n",
    "\n",
    "        # Get the best parameters from grid search\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "        # Save the best parameters to JSON if found\n",
    "        if best_params:\n",
    "            os.makedirs(params_dir, exist_ok=True)\n",
    "            with open(params_file, \"w\") as f:\n",
    "                json.dump(best_params, f, indent=4)\n",
    "\n",
    "    # Train the best model using loaded or selected parameters\n",
    "    if best_params:\n",
    "        best_model = xgb.XGBRegressor(\n",
    "            n_estimators=best_params['n_estimators'],\n",
    "            learning_rate=best_params['learning_rate'],\n",
    "            max_depth=best_params['max_depth'],\n",
    "            min_child_weight=best_params['min_child_weight'],\n",
    "            gamma=best_params['gamma'],\n",
    "            subsample=best_params['subsample'],\n",
    "            colsample_bytree=best_params['colsample_bytree'],\n",
    "            objective='reg:squarederror',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Perform Recursive Feature Elimination (RFE)\n",
    "        rfe = RFE(estimator=best_model, n_features_to_select=3)\n",
    "        rfe.fit(train_x, train_y)\n",
    "\n",
    "        # Get the selected features\n",
    "        selected_features = train_x.columns[rfe.support_]\n",
    "\n",
    "\n",
    "        # Train the model on the selected features\n",
    "        best_model.fit(train_x[selected_features], train_y, verbose=0)\n",
    "\n",
    "        # Make predictions\n",
    "        #predictions = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        predictions_rfe = best_model.predict(test_x[selected_features])\n",
    "\n",
    "        # Calculate RMSE for the RFE model\n",
    "        rmse_rfe = np.sqrt(mean_squared_error(test_y, predictions_rfe))\n",
    "\n",
    "        # Feature importance analysis\n",
    "        feature_importances = best_model.feature_importances_\n",
    "        important_features = selected_features[feature_importances > 0.1]\n",
    "\n",
    "        if len(important_features) > 0:\n",
    "            # Retrain the model using only features with importance > 0.1\n",
    "            best_model.fit(train_x[important_features], train_y, verbose=0)\n",
    "            predictions_important = best_model.predict(test_x[important_features])\n",
    "\n",
    "            # Calculate RMSE for the model trained on important features\n",
    "            rmse_important = np.sqrt(mean_squared_error(test_y, predictions_important))\n",
    "\n",
    "        if rmse_important >rmse_rfe:\n",
    "            predictions = predictions_important\n",
    "        else:\n",
    "            predictions = predictions_rfe\n",
    "        # Save the plot\n",
    "        save_plot(train_y, test_y, predictions, country, indicator, model_name=\"XGBoost\")\n",
    "\n",
    "        return np.sqrt(mean_squared_error(test_y, predictions)), predictions\n",
    "    else:\n",
    "        print(\"No suitable parameters found.\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"../countries.json\", \"r\") as f:\n",
    "    country_names = json.load(f)\n",
    "\n",
    "with open(\"../indicators.json\", \"r\") as f:\n",
    "    indicators = json.load(f)\n",
    "\n",
    "data_folder = \"../data/base\"\n",
    "model_errors_rmse = {}\n",
    "log_data = []\n",
    "country_indicators_plots = {}\n",
    "for country, country_code in country_names.items():\n",
    "    for indicator, indicator_code in indicators.items():\n",
    "        filename = f\"{country.replace(' ', '_')}_{indicator.replace(' ', '_')}.parquet\"\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        \n",
    "        if os.path.exists(filepath):\n",
    "            df = pd.read_parquet(filepath)\n",
    "            if 'Year' in df.columns and 'Value' in df.columns:\n",
    "                df = df.set_index('Year').sort_index()\n",
    "                df.index = pd.to_datetime(df.index, format='%Y')\n",
    "                df = df.dropna()\n",
    "                df = df.drop('Indicator', axis = 1)\n",
    "                df_original = df.copy()\n",
    "                \n",
    "                for lag in range(1, 4):  \n",
    "                    df[f'lag_{lag}'] = df['Value'].shift(lag)\n",
    "                \n",
    "                df['expanding_mean'] = df['Value'].expanding().mean()\n",
    "                df['expanding_std'] = df['Value'].expanding().std()\n",
    "                df['expanding_max'] = df['Value'].expanding().max()\n",
    "                df['expanding_min'] = df['Value'].expanding().min()\n",
    "                \n",
    "                window_size = 3  \n",
    "                df['rolling_mean'] = df['Value'].rolling(window=window_size, min_periods=1).mean()\n",
    "                df['rolling_std'] = df['Value'].rolling(window=window_size, min_periods=1).std()\n",
    "                df['rolling_max'] = df['Value'].rolling(window=window_size, min_periods=1).max()\n",
    "                df['rolling_min'] = df['Value'].rolling(window=window_size, min_periods=1).min()\n",
    "                \n",
    "                \n",
    "                #df = df.dropna()\n",
    "                train_size = int(len(df) * 0.8)\n",
    "                \n",
    "                train_xgb, test_xgb = df.iloc[:train_size], df.iloc[train_size:]\n",
    "                feature_columns = ['rolling_mean','rolling_max', 'rolling_min','rolling_std' ,\n",
    "                                   'expanding_mean', 'expanding_max', 'expanding_min','expanding_std',\n",
    "                                   'lag_1', 'lag_2', 'lag_3', ]\n",
    "                train_x, train_y = train_xgb[feature_columns], train_xgb['Value']\n",
    "                test_x, test_y = test_xgb[feature_columns], test_xgb['Value']\n",
    "                \n",
    "                model_errors_rmse[(country, indicator)] = {}\n",
    "                model_errors_rmse[(country, indicator)]['XGBoost'], xgb_pred = train_xgboost(train_x, train_y, test_x, test_y , country,indicator)\n",
    "                \n",
    "                \n",
    "                sorted_models = sorted(model_errors_rmse[(country, indicator)].items(), key=lambda x: x[1])\n",
    "                log_current_data = []\n",
    "                for rank, (model_name, rmse) in enumerate(sorted_models, start=1):\n",
    "                    log_data.append([country, indicator, model_name, rmse, rank])\n",
    "                    log_current_data.append([country, indicator, model_name, rmse, rank])\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "model =\"XGBoost\"\n",
    "log_dir = f\"../data/{model}_train\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d--%H-%M\")\n",
    "log_filename = os.path.join(log_dir, f\"{model}_error_log_{timestamp}.csv\")\n",
    "\n",
    "log_df = pd.DataFrame(log_data, columns=['Country', 'Indicator', 'Model', 'RMSE', 'Rank'])\n",
    "log_df.to_csv(log_filename, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
